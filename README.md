# Single-Speaker Audio Validation System

A robust deep learning-based audio validation system for identifying single-speaker audio files with minimal noise from rejected datasets. Achieves **91.5% accuracy** using ECAPA-TDNN speaker embeddings and advanced consistency analysis.

## Overview

This system addresses the challenge of rescuing falsely rejected audio files from validation pipelines. It combines state-of-the-art speaker recognition with signal processing to identify genuine single-speaker recordings that were incorrectly discarded.

**Key Results:**
- **43/47 true positives** identified (91.5% accuracy)

## Features

- **ECAPA-TDNN Speaker Recognition**: State-of-the-art 192-dimensional speaker embeddings
- **Gapless Windowing**: Complete audio coverage with 1.5s windows
- **Batch Processing**: Vectorized inference for 4.2Ã— speedup
- **RMS-based SNR**: Robust noise estimation for processed audio
- **Rich Visualizations**: 
  - Speaker embedding PCA plots
  - Temporal consistency graphs
  - SNR distribution histograms
- **Dual Output Formats**: CSV and JSON reports with full metrics

## Installation

### Prerequisites
- Python 3.12+
- Windows/Linux/macOS
- 8GB+ RAM recommended

### Setup

```bash
git clone <repository-url>
cd voicesingle
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### Dependencies

```
torch==2.2.0
torchaudio==2.2.0
speechbrain==1.0.3
numpy<2
huggingface_hub<1.0
librosa
matplotlib
scikit-learn
pandas
tqdm
```

## Usage

### Basic Validation

Validate all audio files in the `data_final` directory:

```bash
python validate_dataset.py
```

This processes:
- `data_final/failed/` - MP3 files
- `data_final/mbti_data/` - WAV files


### Output

The system generates:

**Reports:**
- `failed_report.csv` / `failed_report.json` - Results for MP3 files
- `mbti_report.csv` / `mbti_report.json` - Results for WAV files

**Visualizations:**
- `plots/failed/` - Plots for MP3 files
- `plots/mbti/` - Plots for WAV files

Each file gets three plots:
1. `*_stability.png` - Temporal consistency over time
2. `*_pca.png` - Speaker embedding clusters (2D PCA)
3. `*_dist.png` - SNR distribution histogram

## Architecture

```
audio_validator/
|-- __init__.py          # Package initialization
|-- core.py              # Main validation logic
|-- snr.py               # SNR estimation
|-- speaker.py           # ECAPA-TDNN wrapper
+-- viz.py               # Visualization generation

validate_dataset.py      # Batch processing script
quick_test.py            # Single-file testing
requirements.txt         # Dependencies
technical_report.pdf     # Full technical documentation
```

## Validation Criteria

A file is marked **valid** if it passes all checks:

1. **Not Silent**: Contains actual audio content
2. **Speaker Consistency > 0.25**: Single speaker throughout
3. **Spectral Flatness < 0.5**: Structured signal (not white noise)

**Note:** SNR is calculated but not enforced (informational only).

## Metrics Explained

### Consistency Score
Measures speaker identity stability across the audio:
- **0.40-0.50**: High-confidence single speaker
- **0.25-0.40**: Likely single speaker
- **< 0.25**: Multiple speakers detected

Calculated as mean cosine similarity between all embedding pairs.

### SNR (Signal-to-Noise Ratio)
Energy-based separation of speech vs. silence:
- **> 20 dB**: Clean audio
- **15-20 dB**: Acceptable quality
- **< 15 dB**: Noisy (flagged as warning)

### Spectral Flatness
Measures frequency distribution:
- **< 0.1**: Tonal content (speech/music)
- **> 0.5**: Noise-like signal

## Performance

**Validation Speed:**
- ~60-120 seconds per file (CPU)
- Batch processing: 32 windows simultaneously
- Memory usage: ~300KB per 10-minute file

**Accuracy:**
- Precision: 100% (no false positives)
- Recall: 91.5% (43/47 true positives)
- F1 Score: 0.955

## Example Output

```json
{
  "valid": true,
  "reasons": [],
  "warnings": ["Low SNR 14.8dB"],
  "metrics": {
    "snr": 14.756583213806152,
    "consistency": 0.399964302778244,
    "flatness": 0.02148652
  },
  "filename": "agentofdoubt_audio_part1_dominant.wav"
}
```

## Visualization Interpretation

### Stability Plot
Line graph showing consistency score over time:
- **Flat high line**: Consistent single speaker
- **Drops/spikes**: Speaker changes or noise
- **Red dashed line**: Threshold (0.25)

### PCA Cluster Plot
2D projection of speaker embeddings:
- **Single tight cluster**: One speaker
- **Multiple clusters**: Multiple speakers
- **Scattered points**: High variability

### Distribution Plot
Histogram of audio waveform amplitudes:
- **Narrow peak**: Clean signal
- **Wide spread**: Noisy or dynamic range issues

## Troubleshooting

### Out of Memory Error
For very long files (>10 minutes), reduce batch size in `speaker.py`:
```python
batch_size = 16  # Default: 32
```

### Dependency Conflicts
If you encounter version conflicts after recreating venv:
```bash
pip install torch==2.2.0 torchaudio==2.2.0 --force-reinstall
pip install "numpy<2" "huggingface_hub<1.0"
pip install speechbrain==1.0.3
```

### Model Download Issues
First run downloads ECAPA-TDNN model (~80MB) from HuggingFace:
```
pretrained_models/spkrec-ecapa-voxceleb/
```
Ensure stable internet connection.

## Technical Details

For comprehensive technical documentation including:
- Mathematical formulations
- Algorithm pseudocode
- Architecture diagrams
- Performance analysis
- Research background

See: **`technical_report.pdf`**

## Limitations

1. **Threshold Sensitivity**: Performance depends on consistency threshold calibration
2. **Short Audio**: Files < 3 seconds may produce unreliable results
3. **Processing Time**: CPU-only inference is slow for large datasets


## License

MIT License - See LICENSE file for details

## Acknowledgments

- **SpeechBrain** for ECAPA-TDNN implementation
- **VoxCeleb** dataset for pretrained models
- Research based on Desplanques et al. (2020) ECAPA-TDNN architecture
